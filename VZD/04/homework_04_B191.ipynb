{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol č. 4 - regrese (do 2. ledna)\n",
    "\n",
    "  * Cílem tohoto úkolu je vyzkoušet si řešit regresní problém na reálných (ale celkem vyčištěných) datech.\n",
    "  \n",
    "> **Nejdůležitější na úkolu je to, abyste udělali vše procesně správně: korektní rozdělení datasetu, ladění hyperparametrů, vyhodnocení výsledků atp.**\n",
    "\n",
    "## Dataset\n",
    "\n",
    "  * Zdrojem dat je list *Data* v souboru `Residential-Building-Data-Set.xlsx` na course pages (originál zde: https://archive.ics.uci.edu/ml/datasets/Residential+Building+Data+Set#).\n",
    "  * Popis datasetu najdete na listu *Descriptions* ve stejném souboru.\n",
    "  \n",
    "\n",
    "## Pokyny k vypracování\n",
    "\n",
    "  1. Rozdělte data na trénovací a testovací množinu.\n",
    "  1. Proveďte základní průzkum dat a příp. vyhoďte nezajímavé příznaky.\n",
    "  1. Aplikujte lineární a hřebenovou regresi a výsledky řádně vyhodnoťte:\n",
    "    * K měření chyby použijte `mean_absolute_error`.\n",
    "    * Experimentujte s tvorbou nových příznaků (na základě těch dostupných).\n",
    "    * Experimentujte se standardizací/normalizací dat.\n",
    "    * Vyberte si hyperparametry modelů k ladění a najděte jejich nejlepší hodnoty.\n",
    "  1. Použijte i jiný model než jen lineární a hřebenovou regresi.\n",
    "\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-VZD/homeworks/index.html.\n",
    "  * Odevzdejte pouze tento Jupyter Notebook, opravujíví by neměl nic jiného potřebovat.\n",
    "  * Opravující Vám může umožnit úkol dodělat či opravit a získat tak další body. První verze je ale důležitá a bude-li odbytá, budete za to penalizováni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkce na načtení dat\n",
    "V této úloze máme predikovat dvě výsledné hodnoty \"sales price\" a \"construction costs\" na základě hodnot ekonomických faktorů a faktorů spojených přímo s projektem. \n",
    "\n",
    "Já jsem se rozhodl vždy trénovat 2 modely zvlášt, jeden který bude predikovat \"sales price\" a druhý který bude predikovat \"construction costs\". Výsledné MAE spočítám sečtením chyb každého z modelu a vydělením počtem modelů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', module='sklearn')\n",
    "\n",
    "def LoadData():\n",
    "    path = 'Residential-Building-Data-Set.xlsx'\n",
    "    import pandas\n",
    "    df = pandas.read_excel(path,header=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def ConvertToArray(df):\n",
    "    X, Y1, Y2 = [], [], []\n",
    "    n_of_rows = len(df.index)\n",
    "\n",
    "    for i in range(n_of_rows):\n",
    "        entire_row = list(df.iloc[i])\n",
    "        X.append(entire_row[:-2])\n",
    "        Y1.append(entire_row[-2])\n",
    "        Y2.append(entire_row[-1])\n",
    "\n",
    "    return X, Y1, Y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testování na Hrubých datech\n",
    "Poté co jsme dataset rozdělili na trénovací a testovací množinu budeme nejprve exkluzivně pracovat s trénovací množinou. Na ní zjistíme úspěšnost našich modelů za použití cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results without any normalization or feature engineering:\n",
      "Linear Regression MAE: 78.2963000618238\n",
      "Ridge Regression MAE: 77.89365490770658\n",
      "Random Forest MAE: 101.15629723050026\n"
     ]
    }
   ],
   "source": [
    "print('Results without any normalization or feature engineering:')\n",
    "\n",
    "df = LoadData()\n",
    "X, Y1, Y2 = ConvertToArray(df)\n",
    "delimiter = 330\n",
    "\n",
    "x_test = X[delimiter:]\n",
    "y1_test = Y1[delimiter:]\n",
    "y2_test = Y2[delimiter:]\n",
    "\n",
    "X = X[:delimiter]\n",
    "Y1 = Y1[:delimiter]\n",
    "Y2 = Y2[:delimiter]\n",
    "\n",
    "reg = LinearRegression()\n",
    "res = abs(cross_val_score(reg, X, Y1,cv=10,scoring='neg_mean_absolute_error').mean()) + abs(cross_val_score(reg, X, Y2,cv=10,scoring='neg_mean_absolute_error').mean())\n",
    "res /= 2.0\n",
    "print('Linear Regression MAE:',res)\n",
    "\n",
    "ridge = Ridge()\n",
    "res = abs(cross_val_score(ridge, X, Y1,cv=10,scoring='neg_mean_absolute_error').mean()) + abs(cross_val_score(ridge, X, Y2,cv=10,scoring='neg_mean_absolute_error').mean())\n",
    "res /= 2.0\n",
    "print('Ridge Regression MAE:',res)\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=8, random_state=0)\n",
    "res = abs(cross_val_score(regr, X, Y1,cv=10,scoring='neg_mean_absolute_error').mean()) + abs(cross_val_score(regr, X, Y2,cv=10,scoring='neg_mean_absolute_error').mean())\n",
    "res /= 2.0\n",
    "print('Random Forest MAE:',res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "V datasetu pracujeme s časovými daty. Kdy například feature V-25.3 je hodnota stejné featury jako V-25.1 jen v jiném čase. První funkce TakeFinalFeature zahodí všechny ostatní hodnoty dané feature kromě té poslední. Toto je důležité protože Linearní regrese funguje lépe pokud jsou feature mezi sebou nekorelované.\n",
    "\n",
    "Funkce SelectFeatures zjistí, které znaky jsou nejméně korelované s hodnotami které máme predikovat a tyto feature odstraní. Funkce zjistila že znaky \"Lot area\" a \"Population of the city\" mají nejmenší vliv na výsledek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TakeFinalFeature(df):\n",
    "    for i in range(11,29):\n",
    "        df = df.drop(['V-'+str(i)],axis=1)\n",
    "        for j in range(1,4):\n",
    "            df = df.drop(['V-'+str(i)+'.'+str(j)],axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectFeatures(df):\n",
    "    cor = df.corr()\n",
    "    cor_target1 = abs(cor['V-9'])\n",
    "    relevant_features1 = cor_target1[cor_target1 < 0.2]\n",
    "\n",
    "    cor_target2 = abs(cor['V-10'])\n",
    "    relevant_features2 = cor_target2[cor_target2 < 0.2]\n",
    "\n",
    "    print(relevant_features1)\n",
    "    print(relevant_features2)\n",
    "\n",
    "    df.drop(['V-3','V-28.4'], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testování na datech po feature selection\n",
    "Po aplikování feature selection vidíme, že MAE (mean absolute error) klesl skoro o 10 bodů (zhruba 10%) u všech modelů na trénovací množině."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with feature selection:\n",
      "START QUARTER         0.093030\n",
      "COMPLETION QUARTER    0.003542\n",
      "V-3                   0.163545\n",
      "V-6                   0.192130\n",
      "V-7                   0.139202\n",
      "V-28.1                0.197168\n",
      "V-28.2                0.131822\n",
      "V-28.3                0.040370\n",
      "V-20.4                0.127425\n",
      "Name: V-9, dtype: float64\n",
      "START QUARTER         0.128630\n",
      "COMPLETION QUARTER    0.061487\n",
      "V-3                   0.165161\n",
      "V-28.2                0.126206\n",
      "V-28.3                0.041004\n",
      "Name: V-10, dtype: float64\n",
      "Linear Regression MAE: 69.51894367788947\n",
      "Ridge Regression MAE: 69.37704198079169\n",
      "Random Forest MAE: 94.29449858351447\n"
     ]
    }
   ],
   "source": [
    "print('Results with feature selection:')\n",
    "\n",
    "df = LoadData()\n",
    "df = SelectFeatures(df)\n",
    "df = TakeFinalFeature(df)\n",
    "X, Y1, Y2 = ConvertToArray(df)\n",
    "\n",
    "x_test = X[delimiter:]\n",
    "y1_test = Y1[delimiter:]\n",
    "y2_test = Y2[delimiter:]\n",
    "\n",
    "X = X[:delimiter]\n",
    "Y1 = Y1[:delimiter]\n",
    "Y2 = Y2[:delimiter]\n",
    "\n",
    "reg = LinearRegression()\n",
    "res = abs(cross_val_score(reg, X, Y1,cv=10,scoring='neg_mean_absolute_error').mean()) + abs(cross_val_score(reg, X, Y2,cv=10,scoring='neg_mean_absolute_error').mean())\n",
    "res /= 2.0\n",
    "print('Linear Regression MAE:',res)\n",
    "\n",
    "ridge = Ridge()\n",
    "res = abs(cross_val_score(ridge, X, Y1,cv=10,scoring='neg_mean_absolute_error').mean()) + abs(cross_val_score(ridge, X, Y2,cv=10,scoring='neg_mean_absolute_error').mean())\n",
    "res /= 2.0\n",
    "print('Ridge Regression MAE:',res)\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=8, random_state=0)\n",
    "res = abs(cross_val_score(regr, X, Y1,cv=10,scoring='neg_mean_absolute_error').mean()) + abs(cross_val_score(regr, X, Y2,cv=10,scoring='neg_mean_absolute_error').mean())\n",
    "res /= 2.0\n",
    "print('Random Forest MAE:',res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizace dat\n",
    "V data science se často vyplatí dělat takzvaná standardizace dat. V našem případě využijeme StandardScaler z knihovny sklearn, který pro každý data feature spočítá průmernou hodnotu a rozptyl. Od každé hodnoty dané feature nejprve odečte medián (tím zajistí vycentrování dat) a následně hodnotu vydělí rozptylem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression MAE after standardization: 69.55362524912306\n",
      "Ridge regression MAE after standardization: 65.5800414061934\n",
      "Random forest MAE after standardization: 95.35921156648433\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "transformedX = scaler.transform(X)\n",
    "\n",
    "res = abs(cross_val_score(reg, transformedX, Y1, cv=10, scoring='neg_mean_absolute_error').mean()) + abs(cross_val_score(reg, transformedX, Y2, cv=10, scoring='neg_mean_absolute_error').mean())\n",
    "print('Linear regression MAE after standardization:',res/2.0)\n",
    "\n",
    "res = abs(cross_val_score(ridge, transformedX, Y1, cv=10, scoring='neg_mean_absolute_error').mean()) + abs(cross_val_score(ridge, transformedX, Y2, cv=10, scoring='neg_mean_absolute_error').mean())\n",
    "print('Ridge regression MAE after standardization:',res/2.0)\n",
    "\n",
    "res = abs(cross_val_score(regr, transformedX, Y1, cv=10, scoring='neg_mean_absolute_error').mean()) + abs(cross_val_score(regr, transformedX, Y2, cv=10, scoring='neg_mean_absolute_error').mean())\n",
    "print('Random forest MAE after standardization:',res/2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Výsledky standardizace\n",
    "V našem případě nastala pozitivní změna výsledku kvůli standardizaci pouze u Random Forest, tudíž v našem případě nebudeme nadále standardizaci používat. Kdybychom jí ale chtěli na testovací množinu přeciejn použít, nebudeme testovací množinu znovu fitovat, ale zavoláme pouze funkci transform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hledání hyperparametrů\n",
    "Po nastavení stavového prostoru hyperparametrů tento prostor náhodně prohledáme. Celý stavový prostor má 4*2*5*3*3*2=720 možností. Abychom ušetřili čas, vykoušíme náhodně pouze 100 možností."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse', max_depth=8,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators='warn',\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_state=...rbose=0,\n",
       "                                                   warm_start=False),\n",
       "                   iid='warn', n_iter=100, n_jobs=1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [3, 6, 10, 30, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [20, 50, 100, 200]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find hyperparameters\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [20,50,100,200]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [3,6,10,30]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "grid_search = RandomizedSearchCV(estimator = regr, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=0, random_state=42, n_jobs = 1)\n",
    "grid_search.fit(X,Y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nalezené hyperparametry\n",
    "Zde vidíte nalezené nejlepší parametry a také výsledné MAE na trénovací množině, které je o 3 nižší než s defaultně nastavenými parametry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': True}\n",
      "Best Random forest MAE: 88.406702849819\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters:',grid_search.best_params_)\n",
    "\n",
    "regr = RandomForestRegressor(**(grid_search.best_params_))\n",
    "\n",
    "res = abs(cross_val_score(regr, X, Y1, cv=10, scoring='neg_mean_absolute_error').mean()) + abs(cross_val_score(regr, X, Y2, cv=10, scoring='neg_mean_absolute_error').mean())\n",
    "print('Best Random forest MAE:',res/2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hledání hyperparametrů\n",
    "Obdobně budeme postupovat při hledání hyperparametrů i pro hřebenovou regresi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Ridge(alpha=100, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=None, normalize=False, random_state=None,\n",
       "                             solver='cholesky', tol=0.001),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [0.001, 0.05, 0.2, 1, 3, 10, 100, 300],\n",
       "                         'solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg',\n",
       "                                    'sag', 'saga']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "solver = ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "alpha = [0.001, 0.05,0.2,1,3,10,100,300]\n",
    "\n",
    "# Create the random grid for ridge regression\n",
    "random_grid_ridge = {'solver': solver,\n",
    "               'alpha': alpha,}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = ridge, param_grid = random_grid_ridge, cv = 5, verbose=0)\n",
    "grid_search.fit(X,Y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nalezené hyperparametry\n",
    "Opět vidíme pozitivní efekt použití nalezených hyperparametrů na výsledné MAE na trénovací množině oproti defaultně nastaveným parametrům."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for ridge regression: {'alpha': 100, 'solver': 'cholesky'}\n",
      "Best Ridge regression MAE: 67.28294612570365\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters for ridge regression:',grid_search.best_params_)\n",
    "\n",
    "ridge = Ridge(**(grid_search.best_params_))\n",
    "\n",
    "res = abs(cross_val_score(ridge, X, Y1, cv=10, scoring='neg_mean_absolute_error').mean()) + abs(cross_val_score(ridge, X, Y2, cv=10, scoring='neg_mean_absolute_error').mean())\n",
    "print('Best Ridge regression MAE:',res/2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Výsledek na testovací množině\n",
    "Na závěr naše modely vyhodnotíme na testovací množině, kterou jsme měli celou dobu stranou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random forest MAE on a testing set: 66.37749509314746\n",
      "Best Ridge regression on a testing set: 54.77164935031843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "res = 0\n",
    "\n",
    "regr.fit(X,Y1)\n",
    "pred = regr.predict(x_test)\n",
    "res += mean_absolute_error(pred,y1_test)\n",
    "\n",
    "regr.fit(X,Y2)\n",
    "pred = regr.predict(x_test)\n",
    "res += mean_absolute_error(pred,y2_test)\n",
    "\n",
    "print('Best Random forest MAE on a testing set:',res/2.0)\n",
    "\n",
    "res = 0\n",
    "ridge.fit(X,Y1)\n",
    "pred = ridge.predict(x_test)\n",
    "res += mean_absolute_error(pred,y1_test)\n",
    "\n",
    "ridge.fit(X,Y2)\n",
    "pred = ridge.predict(x_test)\n",
    "res += mean_absolute_error(pred,y2_test)\n",
    "print('Best Ridge regression on a testing set:',res/2.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
